{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import argparse\n",
    "\n",
    "from semanticGAN_code.models.stylegan2_seg import GeneratorSeg\n",
    "from semanticGAN_code.models.encoder_model import FPNEncoder\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torchvision import transforms\n",
    "from semanticGAN_code.models import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rgb(args, mask):\n",
    "    if args.dataset_name == 'celeba-mask':\n",
    "        color_table = torch.tensor(\n",
    "    [[  0,   0,   0],\n",
    "    [ 0,0,205],\n",
    "    [132,112,255],\n",
    "    [ 25,25,112],\n",
    "    [187,255,255],\n",
    "    [ 102,205,170],\n",
    "    [ 227,207,87],\n",
    "    [ 142,142,56]], dtype=torch.float)\n",
    "\n",
    "    else:\n",
    "        raise Exception('No such a dataloader!')\n",
    "\n",
    "    rgb_tensor = F.embedding(mask, color_table).permute(0,3,1,2)\n",
    "    return rgb_tensor\n",
    "\n",
    "def make_mask(args, tensor, threshold=0.5):\n",
    "    if args.seg_dim == 1:\n",
    "        seg_prob = torch.sigmoid(tensor)\n",
    "        seg_mask = torch.zeros_like(tensor)\n",
    "        seg_mask[seg_prob > threshold] = 1.0\n",
    "        seg_mask = (seg_mask.to('cpu')\n",
    "           .mul(255)\n",
    "           .type(torch.uint8)\n",
    "           .permute(0, 2, 3, 1)\n",
    "           .numpy())\n",
    "    else:\n",
    "        seg_prob = torch.argmax(tensor, dim=1)\n",
    "        seg_mask = mask2rgb(args, seg_prob)\n",
    "        seg_mask = (seg_mask.to('cpu')\n",
    "           .type(torch.uint8)\n",
    "           .permute(0, 2, 3, 1)\n",
    "           .numpy())\n",
    "    \n",
    "\n",
    "    return seg_mask\n",
    "\n",
    "def make_image(tensor):\n",
    "    return (\n",
    "        tensor.detach()\n",
    "        .clamp_(min=-1, max=1)\n",
    "        .add(1)\n",
    "        .div_(2)\n",
    "        .mul(255)\n",
    "        .type(torch.uint8)\n",
    "        .permute(0, 2, 3, 1)\n",
    "        .to('cpu')\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "\n",
    "def overlay_img_and_mask(args, img_pil, mask_pil, alpha=0.3):\n",
    "    img_pil = img_pil.convert('RGBA')\n",
    "    mask_pil = mask_pil.convert('RGBA')\n",
    "\n",
    "    overlay_pil = Image.blend(img_pil, mask_pil, alpha)\n",
    "    \n",
    "    return overlay_pil\n",
    "\n",
    "def noise_regularize(noises):\n",
    "    loss = 0\n",
    "\n",
    "    for noise in noises:\n",
    "        size = noise.shape[2]\n",
    "\n",
    "        while True:\n",
    "            loss = (\n",
    "                loss\n",
    "                + (noise * torch.roll(noise, shifts=1, dims=3)).mean().pow(2)\n",
    "                + (noise * torch.roll(noise, shifts=1, dims=2)).mean().pow(2)\n",
    "            )\n",
    "\n",
    "            if size <= 8:\n",
    "                break\n",
    "\n",
    "            noise = noise.reshape([1, 1, size // 2, 2, size // 2, 2])\n",
    "            noise = noise.mean([3, 5])\n",
    "            size //= 2\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def noise_normalize_(noises):\n",
    "    for noise in noises:\n",
    "        mean = noise.mean()\n",
    "        std = noise.std()\n",
    "\n",
    "        noise.data.add_(-mean).div_(std)\n",
    "\n",
    "def get_lr(t, initial_lr, rampdown=0.25, rampup=0.05):\n",
    "    lr_ramp = min(1, (1 - t) / rampdown)\n",
    "    lr_ramp = 0.5 - 0.5 * math.cos(lr_ramp * math.pi)\n",
    "    lr_ramp = lr_ramp * min(1, t / rampup)\n",
    "\n",
    "    return initial_lr * lr_ramp\n",
    "\n",
    "def get_transformation(args):\n",
    "    if args.dataset_name == 'celeba-mask':\n",
    "        transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "    ]\n",
    "    )\n",
    "    else:\n",
    "        raise Exception('No such a dataloader!')\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--dataset_name', type=str, help='segmentation dataloader name [celeba-mask|cxr|isic]', default='celeba-mask')\n",
    "parser.add_argument('--size', type=int, default=256)\n",
    "parser.add_argument('--channel_multiplier', type=int, default=2)\n",
    "parser.add_argument('--image_mode', type=str, default='RGB')\n",
    "parser.add_argument('--batch_size', type=int, default=1)\n",
    "parser.add_argument('--seg_dim', type=int, default=8)\n",
    "parser.add_argument('--gpu_ids', type=int, nargs='+', default=[0])\n",
    "\n",
    "parser.add_argument('--mean_init', action='store_true', help='initialize latent code with mean')\n",
    "parser.add_argument('--no_noises', action='store_true')\n",
    "parser.add_argument('--w_plus', action='store_true', help='optimize in w+ space, otherwise w space')\n",
    "\n",
    "parser.add_argument('--save_latent', action='store_true')\n",
    "parser.add_argument('--save_steps', action='store_true', help='if to save intermediate optimization results')\n",
    "\n",
    "parser.add_argument('--truncation', type=float, default=1, help='truncation tricky, trade-off between quality and diversity')\n",
    "parser.add_argument('--truncation_mean', type=int, default=4096)\n",
    "\n",
    "parser.add_argument('--lr_rampup', type=float, default=0.05)\n",
    "parser.add_argument('--lr_rampdown', type=float, default=0.25)\n",
    "parser.add_argument('--lr', type=float, default=0.1)\n",
    "parser.add_argument('--noise', type=float, default=0.05)\n",
    "parser.add_argument('--noise_ramp', type=float, default=0.75)\n",
    "parser.add_argument('--step', type=int, default=100, help='optimization steps [100-500 should give good results]')\n",
    "parser.add_argument('--noise_regularize', type=float, default=1e2)\n",
    "parser.add_argument('--lambda_mse', type=float, default=0.1)\n",
    "parser.add_argument('--lambda_mean', type=float, default=0.01)\n",
    "parser.add_argument('--lambda_label', type=float, default=1.0)\n",
    "parser.add_argument('--lambda_encoder', type=float, default=1e-3)\n",
    "parser.add_argument('--lambda_encoder_init', type=float, default=0.0)\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "args.latent = 512\n",
    "args.n_mlp = 8\n",
    "args.step=400\n",
    "tru_mean_latent = None\n",
    "d_input_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('semanticGAN_code/semanticGAN/checkpoint/run-Sep02_15-35-55/ckpt/146000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPNEncoder(\n",
       "  (FPN_module): FPN(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (toplayer): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (smooth1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (smooth2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (smooth3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (latlayer1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (latlayer2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (latlayer3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (course_styles): ModuleList(\n",
       "    (0-2): 3 x ToStyleCode(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "      (linear): EqualLinear(512, 512)\n",
       "    )\n",
       "  )\n",
       "  (medium_styles): ModuleList(\n",
       "    (0-3): 4 x ToStyleCode(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (9): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "      (linear): EqualLinear(512, 512)\n",
       "    )\n",
       "  )\n",
       "  (fine_styles): ModuleList(\n",
       "    (0-6): 7 x ToStyleCode(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (9): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (11): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "      (linear): EqualLinear(512, 512)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_ema = GeneratorSeg(args.size, args.latent, args.n_mlp, seg_dim=args.seg_dim, image_mode=args.image_mode,\n",
    "        channel_multiplier=args.channel_multiplier\n",
    "    ).to(device)\n",
    "g_ema.load_state_dict(checkpoint['g_ema'], strict=False)\n",
    "g_ema.eval()\n",
    "\n",
    "encoder = FPNEncoder(input_dim=d_input_dim, n_latent=g_ema.n_latent).to(device)\n",
    "encoder.load_state_dict(checkpoint['e'])\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Perceptual loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theloni/miniconda/envs/missing-you/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/theloni/miniconda/envs/missing-you/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /net/flood/home/theloni/missing-you/semanticGAN_code/models/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n"
     ]
    }
   ],
   "source": [
    "percept = lpips.PerceptualLoss(\n",
    "        model='net-lin', net='vgg', use_gpu=device.startswith('cuda')\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 256\n",
    "transform = get_transformation(args)\n",
    "img_p = \"test_img_3.png\"\n",
    "pbar = range(args.step)\n",
    "latent_path = []\n",
    "# load target image\n",
    "target_pil = Image.open(img_p).convert(args.image_mode).resize((args.size,args.size), resample=Image.LANCZOS)\n",
    "\n",
    "target_img_tensor = transform(target_pil).unsqueeze(0).to(device)\n",
    "noises = g_ema.make_noise()\n",
    "with torch.no_grad():\n",
    "    latent_in = encoder(target_img_tensor)\n",
    "    latent_enc_init = latent_in.clone().detach()\n",
    "latent_in.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam([latent_in] + noises, lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p loss: 0.5365; noise regularize:0.6037; mse loss: 0.1203; encoder loss: 1349000238202880.0000; encoder init loss: 0.0000; \n",
      "p loss: 0.5362; noise regularize:0.5959; mse loss: 0.1199; encoder loss: 1359528947875840.0000; encoder init loss: 0.0000; \n",
      "p loss: 0.5332; noise regularize:0.5959; mse loss: 0.1196; encoder loss: 1222945632419840.0000; encoder init loss: 0.0000; \n",
      "p loss: 0.5287; noise regularize:0.5959; mse loss: 0.1192; encoder loss: 997738753818624.0000; encoder init loss: 0.0001; \n",
      "p loss: 0.5243; noise regularize:0.5959; mse loss: 0.1187; encoder loss: 762867125059584.0000; encoder init loss: 0.0003; \n",
      "p loss: 0.5201; noise regularize:0.5959; mse loss: 0.1173; encoder loss: 569557089517568.0000; encoder init loss: 0.0008; \n",
      "p loss: 0.5153; noise regularize:0.5959; mse loss: 0.1159; encoder loss: 451825929027584.0000; encoder init loss: 0.0017; \n",
      "p loss: 0.5116; noise regularize:0.5959; mse loss: 0.1166; encoder loss: 368045579042816.0000; encoder init loss: 0.0030; \n",
      "p loss: 0.5087; noise regularize:0.5959; mse loss: 0.1166; encoder loss: 324107157635072.0000; encoder init loss: 0.0047; \n",
      "p loss: 0.5041; noise regularize:0.5959; mse loss: 0.1126; encoder loss: 289317419220992.0000; encoder init loss: 0.0068; \n",
      "p loss: 0.5002; noise regularize:0.5959; mse loss: 0.1053; encoder loss: 264476318236672.0000; encoder init loss: 0.0096; \n",
      "p loss: 0.4962; noise regularize:0.5959; mse loss: 0.1004; encoder loss: 227980555059200.0000; encoder init loss: 0.0132; \n",
      "p loss: 0.4936; noise regularize:0.5959; mse loss: 0.0998; encoder loss: 183872952205312.0000; encoder init loss: 0.0177; \n",
      "p loss: 0.4920; noise regularize:0.5959; mse loss: 0.1011; encoder loss: 155340477825024.0000; encoder init loss: 0.0229; \n",
      "p loss: 0.4877; noise regularize:0.5959; mse loss: 0.1025; encoder loss: 156093556719616.0000; encoder init loss: 0.0291; \n",
      "p loss: 0.4834; noise regularize:0.5959; mse loss: 0.1040; encoder loss: 171681486209024.0000; encoder init loss: 0.0365; \n",
      "p loss: 0.4801; noise regularize:0.5959; mse loss: 0.1070; encoder loss: 161618042290176.0000; encoder init loss: 0.0452; \n",
      "p loss: 0.4777; noise regularize:0.5959; mse loss: 0.1070; encoder loss: 142129577852928.0000; encoder init loss: 0.0554; \n",
      "p loss: 0.4750; noise regularize:0.5959; mse loss: 0.1004; encoder loss: 153883611496448.0000; encoder init loss: 0.0669; \n",
      "p loss: 0.4731; noise regularize:0.5959; mse loss: 0.0980; encoder loss: 137458960302080.0000; encoder init loss: 0.0800; \n",
      "p loss: 0.4718; noise regularize:0.5959; mse loss: 0.0973; encoder loss: 84172685180928.0000; encoder init loss: 0.0953; \n",
      "p loss: 0.4680; noise regularize:0.5959; mse loss: 0.0958; encoder loss: 116212134576128.0000; encoder init loss: 0.1122; \n",
      "p loss: 0.4662; noise regularize:0.5959; mse loss: 0.0954; encoder loss: 153283691806720.0000; encoder init loss: 0.1305; \n",
      "p loss: 0.4632; noise regularize:0.5959; mse loss: 0.0956; encoder loss: 138680601673728.0000; encoder init loss: 0.1500; \n",
      "p loss: 0.4625; noise regularize:0.5959; mse loss: 0.0955; encoder loss: 186633643098112.0000; encoder init loss: 0.1707; \n",
      "p loss: 0.4602; noise regularize:0.5959; mse loss: 0.0951; encoder loss: 204428833456128.0000; encoder init loss: 0.1927; \n",
      "p loss: 0.4579; noise regularize:0.5959; mse loss: 0.0940; encoder loss: 137086749376512.0000; encoder init loss: 0.2159; \n",
      "p loss: 0.4556; noise regularize:0.5959; mse loss: 0.0926; encoder loss: 114678806085632.0000; encoder init loss: 0.2403; \n",
      "p loss: 0.4531; noise regularize:0.5959; mse loss: 0.0923; encoder loss: 130710702653440.0000; encoder init loss: 0.2658; \n",
      "p loss: 0.4511; noise regularize:0.5959; mse loss: 0.0916; encoder loss: 129530266124288.0000; encoder init loss: 0.2927; \n",
      "p loss: 0.4499; noise regularize:0.5959; mse loss: 0.0914; encoder loss: 115556791353344.0000; encoder init loss: 0.3208; \n",
      "p loss: 0.4489; noise regularize:0.5959; mse loss: 0.0916; encoder loss: 148090807910400.0000; encoder init loss: 0.3498; \n",
      "p loss: 0.4455; noise regularize:0.5959; mse loss: 0.0912; encoder loss: 176000176488448.0000; encoder init loss: 0.3800; \n",
      "p loss: 0.4458; noise regularize:0.5959; mse loss: 0.0912; encoder loss: 190376270888960.0000; encoder init loss: 0.4114; \n",
      "p loss: 0.4429; noise regularize:0.5959; mse loss: 0.0901; encoder loss: 219638503833600.0000; encoder init loss: 0.4435; \n",
      "p loss: 0.4424; noise regularize:0.5959; mse loss: 0.0892; encoder loss: 251748182654976.0000; encoder init loss: 0.4766; \n",
      "p loss: 0.4399; noise regularize:0.5959; mse loss: 0.0891; encoder loss: 211934607572992.0000; encoder init loss: 0.5113; \n",
      "p loss: 0.4394; noise regularize:0.5959; mse loss: 0.0864; encoder loss: 169396311949312.0000; encoder init loss: 0.5473; \n",
      "p loss: 0.4379; noise regularize:0.5959; mse loss: 0.0862; encoder loss: 258848216580096.0000; encoder init loss: 0.5841; \n",
      "p loss: 0.4366; noise regularize:0.5959; mse loss: 0.0859; encoder loss: 268056324472832.0000; encoder init loss: 0.6227; \n",
      "p loss: 0.4341; noise regularize:0.5959; mse loss: 0.0870; encoder loss: 231641830129664.0000; encoder init loss: 0.6625; \n",
      "p loss: 0.4353; noise regularize:0.5959; mse loss: 0.0877; encoder loss: 252975134015488.0000; encoder init loss: 0.7035; \n",
      "p loss: 0.4329; noise regularize:0.5959; mse loss: 0.0872; encoder loss: 266801657151488.0000; encoder init loss: 0.7458; \n",
      "p loss: 0.4330; noise regularize:0.5959; mse loss: 0.0872; encoder loss: 276473688621056.0000; encoder init loss: 0.7894; \n",
      "p loss: 0.4313; noise regularize:0.5959; mse loss: 0.0864; encoder loss: 253484758728704.0000; encoder init loss: 0.8346; \n",
      "p loss: 0.4307; noise regularize:0.5959; mse loss: 0.0865; encoder loss: 334906081148928.0000; encoder init loss: 0.8812; \n",
      "p loss: 0.4291; noise regularize:0.5959; mse loss: 0.0865; encoder loss: 326570925359104.0000; encoder init loss: 0.9290; \n",
      "p loss: 0.4270; noise regularize:0.5959; mse loss: 0.0872; encoder loss: 210955187257344.0000; encoder init loss: 0.9779; \n",
      "p loss: 0.4279; noise regularize:0.5959; mse loss: 0.0876; encoder loss: 160742338723840.0000; encoder init loss: 1.0283; \n",
      "p loss: 0.4246; noise regularize:0.5959; mse loss: 0.0865; encoder loss: 221742534492160.0000; encoder init loss: 1.0797; \n",
      "p loss: 0.4247; noise regularize:0.5959; mse loss: 0.0867; encoder loss: 273012632846336.0000; encoder init loss: 1.1324; \n",
      "p loss: 0.4236; noise regularize:0.5959; mse loss: 0.0866; encoder loss: 228740596498432.0000; encoder init loss: 1.1864; \n",
      "p loss: 0.4230; noise regularize:0.5959; mse loss: 0.0860; encoder loss: 206938704969728.0000; encoder init loss: 1.2415; \n",
      "p loss: 0.4211; noise regularize:0.5959; mse loss: 0.0850; encoder loss: 216663936991232.0000; encoder init loss: 1.2976; \n",
      "p loss: 0.4212; noise regularize:0.5959; mse loss: 0.0845; encoder loss: 210474301915136.0000; encoder init loss: 1.3549; \n",
      "p loss: 0.4196; noise regularize:0.5959; mse loss: 0.0842; encoder loss: 170431365513216.0000; encoder init loss: 1.4139; \n",
      "p loss: 0.4190; noise regularize:0.5959; mse loss: 0.0847; encoder loss: 178582257139712.0000; encoder init loss: 1.4744; \n",
      "p loss: 0.4183; noise regularize:0.5959; mse loss: 0.0849; encoder loss: 206885521195008.0000; encoder init loss: 1.5367; \n",
      "p loss: 0.4182; noise regularize:0.5959; mse loss: 0.0848; encoder loss: 208313648152576.0000; encoder init loss: 1.6001; \n",
      "p loss: 0.4168; noise regularize:0.5959; mse loss: 0.0831; encoder loss: 184300167233536.0000; encoder init loss: 1.6650; \n",
      "p loss: 0.4163; noise regularize:0.5959; mse loss: 0.0829; encoder loss: 164197874794496.0000; encoder init loss: 1.7309; \n",
      "p loss: 0.4157; noise regularize:0.5959; mse loss: 0.0828; encoder loss: 161005120258048.0000; encoder init loss: 1.7983; \n",
      "p loss: 0.4135; noise regularize:0.5959; mse loss: 0.0824; encoder loss: 201796404379648.0000; encoder init loss: 1.8672; \n",
      "p loss: 0.4129; noise regularize:0.5959; mse loss: 0.0820; encoder loss: 201820395798528.0000; encoder init loss: 1.9380; \n",
      "p loss: 0.4126; noise regularize:0.5959; mse loss: 0.0820; encoder loss: 167149020643328.0000; encoder init loss: 2.0100; \n",
      "p loss: 0.4143; noise regularize:0.5959; mse loss: 0.0827; encoder loss: 207401185705984.0000; encoder init loss: 2.0831; \n",
      "p loss: 0.4111; noise regularize:0.5959; mse loss: 0.0815; encoder loss: 215310250541056.0000; encoder init loss: 2.1586; \n",
      "p loss: 0.4104; noise regularize:0.5959; mse loss: 0.0818; encoder loss: 189792105005056.0000; encoder init loss: 2.2353; \n",
      "p loss: 0.4104; noise regularize:0.5959; mse loss: 0.0816; encoder loss: 201665642758144.0000; encoder init loss: 2.3137; \n",
      "p loss: 0.4089; noise regularize:0.5959; mse loss: 0.0807; encoder loss: 165221419188224.0000; encoder init loss: 2.3938; \n",
      "p loss: 0.4093; noise regularize:0.5959; mse loss: 0.0806; encoder loss: 177669878579200.0000; encoder init loss: 2.4754; \n",
      "p loss: 0.4084; noise regularize:0.5959; mse loss: 0.0805; encoder loss: 194608894050304.0000; encoder init loss: 2.5576; \n",
      "p loss: 0.4071; noise regularize:0.5959; mse loss: 0.0807; encoder loss: 193117516988416.0000; encoder init loss: 2.6415; \n",
      "p loss: 0.4069; noise regularize:0.5959; mse loss: 0.0810; encoder loss: 194794718494720.0000; encoder init loss: 2.7272; \n",
      "p loss: 0.4060; noise regularize:0.5959; mse loss: 0.0811; encoder loss: 197438807736320.0000; encoder init loss: 2.8139; \n",
      "p loss: 0.4048; noise regularize:0.5959; mse loss: 0.0805; encoder loss: 162853348704256.0000; encoder init loss: 2.9026; \n",
      "p loss: 0.4062; noise regularize:0.5959; mse loss: 0.0803; encoder loss: 139365716066304.0000; encoder init loss: 2.9932; \n",
      "p loss: 0.4043; noise regularize:0.5959; mse loss: 0.0799; encoder loss: 175738351255552.0000; encoder init loss: 3.0852; \n",
      "p loss: 0.4067; noise regularize:0.5959; mse loss: 0.0809; encoder loss: 212979341590528.0000; encoder init loss: 3.1788; \n",
      "p loss: 0.4032; noise regularize:0.5959; mse loss: 0.0801; encoder loss: 181664802144256.0000; encoder init loss: 3.2749; \n",
      "p loss: 0.4063; noise regularize:0.5959; mse loss: 0.0801; encoder loss: 149240785403904.0000; encoder init loss: 3.3728; \n",
      "p loss: 0.4102; noise regularize:0.5959; mse loss: 0.0805; encoder loss: 201023511592960.0000; encoder init loss: 3.4714; \n",
      "p loss: 0.4059; noise regularize:0.5959; mse loss: 0.0801; encoder loss: 232950503309312.0000; encoder init loss: 3.5722; \n",
      "p loss: 0.4063; noise regularize:0.5959; mse loss: 0.0825; encoder loss: 157206657892352.0000; encoder init loss: 3.6751; \n",
      "p loss: 0.4021; noise regularize:0.5959; mse loss: 0.0797; encoder loss: 145708292243456.0000; encoder init loss: 3.7790; \n",
      "p loss: 0.4036; noise regularize:0.5959; mse loss: 0.0791; encoder loss: 160124131868672.0000; encoder init loss: 3.8850; \n",
      "p loss: 0.4017; noise regularize:0.5959; mse loss: 0.0790; encoder loss: 170197373681664.0000; encoder init loss: 3.9919; \n",
      "p loss: 0.4014; noise regularize:0.5959; mse loss: 0.0800; encoder loss: 166276605411328.0000; encoder init loss: 4.0995; \n",
      "p loss: 0.3998; noise regularize:0.5959; mse loss: 0.0794; encoder loss: 147113602187264.0000; encoder init loss: 4.2084; \n",
      "p loss: 0.3988; noise regularize:0.5959; mse loss: 0.0780; encoder loss: 152878287159296.0000; encoder init loss: 4.3182; \n",
      "p loss: 0.3998; noise regularize:0.5959; mse loss: 0.0782; encoder loss: 159094581231616.0000; encoder init loss: 4.4302; \n",
      "p loss: 0.3996; noise regularize:0.5959; mse loss: 0.0796; encoder loss: 175615223267328.0000; encoder init loss: 4.5434; \n",
      "p loss: 0.3987; noise regularize:0.5959; mse loss: 0.0813; encoder loss: 191890196529152.0000; encoder init loss: 4.6569; \n",
      "p loss: 0.4002; noise regularize:0.5959; mse loss: 0.0799; encoder loss: 213792013156352.0000; encoder init loss: 4.7719; \n",
      "p loss: 0.3994; noise regularize:0.5959; mse loss: 0.0808; encoder loss: 180520277245952.0000; encoder init loss: 4.8878; \n",
      "p loss: 0.3981; noise regularize:0.5959; mse loss: 0.0778; encoder loss: 144100011540480.0000; encoder init loss: 5.0058; \n",
      "p loss: 0.3965; noise regularize:0.5959; mse loss: 0.0798; encoder loss: 137839845048320.0000; encoder init loss: 5.1233; \n",
      "p loss: 0.3948; noise regularize:0.5959; mse loss: 0.0802; encoder loss: 137496750981120.0000; encoder init loss: 5.2434; \n",
      "p loss: 0.3974; noise regularize:0.5959; mse loss: 0.0792; encoder loss: 139766020440064.0000; encoder init loss: 5.3663; \n",
      "p loss: 0.3934; noise regularize:0.5959; mse loss: 0.0777; encoder loss: 161723503869952.0000; encoder init loss: 5.4887; \n",
      "p loss: 0.3963; noise regularize:0.5959; mse loss: 0.0779; encoder loss: 157668836638720.0000; encoder init loss: 5.6126; \n",
      "p loss: 0.3954; noise regularize:0.5959; mse loss: 0.0803; encoder loss: 153798785892352.0000; encoder init loss: 5.7382; \n",
      "p loss: 0.3944; noise regularize:0.5959; mse loss: 0.0807; encoder loss: 187084597886976.0000; encoder init loss: 5.8643; \n",
      "p loss: 0.3931; noise regularize:0.5959; mse loss: 0.0790; encoder loss: 193199607906304.0000; encoder init loss: 5.9927; \n",
      "p loss: 0.3932; noise regularize:0.5959; mse loss: 0.0782; encoder loss: 140349641064448.0000; encoder init loss: 6.1236; \n",
      "p loss: 0.3927; noise regularize:0.5959; mse loss: 0.0783; encoder loss: 128861106864128.0000; encoder init loss: 6.2546; \n",
      "p loss: 0.3920; noise regularize:0.5959; mse loss: 0.0776; encoder loss: 159238982729728.0000; encoder init loss: 6.3867; \n",
      "p loss: 0.3909; noise regularize:0.5959; mse loss: 0.0778; encoder loss: 164285854515200.0000; encoder init loss: 6.5210; \n",
      "p loss: 0.3914; noise regularize:0.5959; mse loss: 0.0787; encoder loss: 144397706461184.0000; encoder init loss: 6.6563; \n",
      "p loss: 0.3902; noise regularize:0.5959; mse loss: 0.0778; encoder loss: 146125642268672.0000; encoder init loss: 6.7941; \n",
      "p loss: 0.3901; noise regularize:0.5959; mse loss: 0.0775; encoder loss: 155821145063424.0000; encoder init loss: 6.9333; \n",
      "p loss: 0.3890; noise regularize:0.5959; mse loss: 0.0784; encoder loss: 159762784190464.0000; encoder init loss: 7.0744; \n",
      "p loss: 0.3881; noise regularize:0.5959; mse loss: 0.0784; encoder loss: 148449068580864.0000; encoder init loss: 7.2171; \n",
      "p loss: 0.3894; noise regularize:0.5959; mse loss: 0.0780; encoder loss: 135649814380544.0000; encoder init loss: 7.3613; \n",
      "p loss: 0.3866; noise regularize:0.5959; mse loss: 0.0769; encoder loss: 141818679263232.0000; encoder init loss: 7.5067; \n",
      "p loss: 0.3889; noise regularize:0.5959; mse loss: 0.0770; encoder loss: 123279939469312.0000; encoder init loss: 7.6547; \n",
      "p loss: 0.3896; noise regularize:0.5959; mse loss: 0.0772; encoder loss: 146440030519296.0000; encoder init loss: 7.8029; \n",
      "p loss: 0.3880; noise regularize:0.5959; mse loss: 0.0777; encoder loss: 145815850975232.0000; encoder init loss: 7.9537; \n",
      "p loss: 0.3871; noise regularize:0.5959; mse loss: 0.0778; encoder loss: 115772110143488.0000; encoder init loss: 8.1064; \n",
      "p loss: 0.3849; noise regularize:0.5959; mse loss: 0.0767; encoder loss: 141485617971200.0000; encoder init loss: 8.2603; \n",
      "p loss: 0.3869; noise regularize:0.5959; mse loss: 0.0762; encoder loss: 144898036596736.0000; encoder init loss: 8.4161; \n",
      "p loss: 0.3870; noise regularize:0.5959; mse loss: 0.0775; encoder loss: 126911334318080.0000; encoder init loss: 8.5736; \n",
      "p loss: 0.3882; noise regularize:0.5959; mse loss: 0.0778; encoder loss: 104477604446208.0000; encoder init loss: 8.7321; \n",
      "p loss: 0.3877; noise regularize:0.5959; mse loss: 0.0758; encoder loss: 154747923333120.0000; encoder init loss: 8.8912; \n",
      "p loss: 0.3864; noise regularize:0.5959; mse loss: 0.0766; encoder loss: 134264704204800.0000; encoder init loss: 9.0511; \n",
      "p loss: 0.3873; noise regularize:0.5959; mse loss: 0.0779; encoder loss: 85722967048192.0000; encoder init loss: 9.2123; \n",
      "p loss: 0.3840; noise regularize:0.5959; mse loss: 0.0759; encoder loss: 112021647392768.0000; encoder init loss: 9.3769; \n",
      "p loss: 0.3866; noise regularize:0.5959; mse loss: 0.0760; encoder loss: 151134530437120.0000; encoder init loss: 9.5421; \n",
      "p loss: 0.3826; noise regularize:0.5959; mse loss: 0.0786; encoder loss: 147499562041344.0000; encoder init loss: 9.7092; \n",
      "p loss: 0.3856; noise regularize:0.5959; mse loss: 0.0784; encoder loss: 111962499317760.0000; encoder init loss: 9.8769; \n",
      "p loss: 0.3824; noise regularize:0.5959; mse loss: 0.0767; encoder loss: 135170069889024.0000; encoder init loss: 10.0450; \n",
      "p loss: 0.3858; noise regularize:0.5959; mse loss: 0.0756; encoder loss: 165696432504832.0000; encoder init loss: 10.2157; \n",
      "p loss: 0.3840; noise regularize:0.5959; mse loss: 0.0768; encoder loss: 144448272990208.0000; encoder init loss: 10.3859; \n",
      "p loss: 0.3817; noise regularize:0.5959; mse loss: 0.0776; encoder loss: 125422213791744.0000; encoder init loss: 10.5608; \n",
      "p loss: 0.3850; noise regularize:0.5959; mse loss: 0.0768; encoder loss: 129373432709120.0000; encoder init loss: 10.7370; \n",
      "p loss: 0.3854; noise regularize:0.5959; mse loss: 0.0753; encoder loss: 125509228822528.0000; encoder init loss: 10.9116; \n",
      "p loss: 0.3829; noise regularize:0.5959; mse loss: 0.0752; encoder loss: 113627176632320.0000; encoder init loss: 11.0904; \n",
      "p loss: 0.3818; noise regularize:0.5959; mse loss: 0.0764; encoder loss: 134073586548736.0000; encoder init loss: 11.2707; \n",
      "p loss: 0.3850; noise regularize:0.5959; mse loss: 0.0772; encoder loss: 163602417844224.0000; encoder init loss: 11.4520; \n",
      "p loss: 0.3809; noise regularize:0.5959; mse loss: 0.0762; encoder loss: 165452877660160.0000; encoder init loss: 11.6355; \n",
      "p loss: 0.3866; noise regularize:0.5959; mse loss: 0.0759; encoder loss: 126919303495680.0000; encoder init loss: 11.8218; \n",
      "p loss: 0.3835; noise regularize:0.5959; mse loss: 0.0760; encoder loss: 144602807926784.0000; encoder init loss: 12.0094; \n",
      "p loss: 0.3858; noise regularize:0.5959; mse loss: 0.0775; encoder loss: 141033891430400.0000; encoder init loss: 12.1976; \n",
      "p loss: 0.3805; noise regularize:0.5959; mse loss: 0.0774; encoder loss: 160162182594560.0000; encoder init loss: 12.3872; \n",
      "p loss: 0.3843; noise regularize:0.5959; mse loss: 0.0769; encoder loss: 138890048438272.0000; encoder init loss: 12.5785; \n",
      "p loss: 0.3805; noise regularize:0.5959; mse loss: 0.0760; encoder loss: 127700140294144.0000; encoder init loss: 12.7718; \n",
      "p loss: 0.3825; noise regularize:0.5959; mse loss: 0.0765; encoder loss: 123960658231296.0000; encoder init loss: 12.9693; \n",
      "p loss: 0.3806; noise regularize:0.5959; mse loss: 0.0770; encoder loss: 145719918854144.0000; encoder init loss: 13.1652; \n",
      "p loss: 0.3804; noise regularize:0.5959; mse loss: 0.0768; encoder loss: 177471538331648.0000; encoder init loss: 13.3627; \n",
      "p loss: 0.3822; noise regularize:0.5959; mse loss: 0.0756; encoder loss: 164122595426304.0000; encoder init loss: 13.5651; \n",
      "p loss: 0.3784; noise regularize:0.5959; mse loss: 0.0751; encoder loss: 131017474048000.0000; encoder init loss: 13.7685; \n",
      "p loss: 0.3823; noise regularize:0.5959; mse loss: 0.0765; encoder loss: 129461865414656.0000; encoder init loss: 13.9700; \n",
      "p loss: 0.3777; noise regularize:0.5959; mse loss: 0.0761; encoder loss: 155229848862720.0000; encoder init loss: 14.1705; \n",
      "p loss: 0.3799; noise regularize:0.5959; mse loss: 0.0766; encoder loss: 157874206539776.0000; encoder init loss: 14.3729; \n",
      "p loss: 0.3793; noise regularize:0.5959; mse loss: 0.0751; encoder loss: 133312781746176.0000; encoder init loss: 14.5761; \n",
      "p loss: 0.3781; noise regularize:0.5959; mse loss: 0.0751; encoder loss: 133105683791872.0000; encoder init loss: 14.7816; \n",
      "p loss: 0.3787; noise regularize:0.5959; mse loss: 0.0762; encoder loss: 126760305819648.0000; encoder init loss: 14.9868; \n",
      "p loss: 0.3767; noise regularize:0.5959; mse loss: 0.0764; encoder loss: 135651424993280.0000; encoder init loss: 15.1951; \n",
      "p loss: 0.3781; noise regularize:0.5959; mse loss: 0.0754; encoder loss: 119638251798528.0000; encoder init loss: 15.4045; \n",
      "p loss: 0.3768; noise regularize:0.5959; mse loss: 0.0751; encoder loss: 102395535163392.0000; encoder init loss: 15.6155; \n",
      "p loss: 0.3771; noise regularize:0.5959; mse loss: 0.0758; encoder loss: 117682456231936.0000; encoder init loss: 15.8258; \n",
      "p loss: 0.3762; noise regularize:0.5959; mse loss: 0.0763; encoder loss: 151776158285824.0000; encoder init loss: 16.0416; \n",
      "p loss: 0.3764; noise regularize:0.5959; mse loss: 0.0766; encoder loss: 175995260764160.0000; encoder init loss: 16.2568; \n",
      "p loss: 0.3763; noise regularize:0.5959; mse loss: 0.0759; encoder loss: 156356371808256.0000; encoder init loss: 16.4726; \n",
      "p loss: 0.3754; noise regularize:0.5959; mse loss: 0.0748; encoder loss: 139126674292736.0000; encoder init loss: 16.6919; \n",
      "p loss: 0.3745; noise regularize:0.5959; mse loss: 0.0742; encoder loss: 163975308247040.0000; encoder init loss: 16.9123; \n",
      "p loss: 0.3741; noise regularize:0.5959; mse loss: 0.0749; encoder loss: 168873248686080.0000; encoder init loss: 17.1360; \n",
      "p loss: 0.3735; noise regularize:0.5959; mse loss: 0.0761; encoder loss: 140951884398592.0000; encoder init loss: 17.3613; \n",
      "p loss: 0.3739; noise regularize:0.5959; mse loss: 0.0763; encoder loss: 133541950128128.0000; encoder init loss: 17.5856; \n",
      "p loss: 0.3728; noise regularize:0.5959; mse loss: 0.0751; encoder loss: 130202453671936.0000; encoder init loss: 17.8116; \n",
      "p loss: 0.3724; noise regularize:0.5959; mse loss: 0.0750; encoder loss: 117569008697344.0000; encoder init loss: 18.0403; \n",
      "p loss: 0.3715; noise regularize:0.5959; mse loss: 0.0745; encoder loss: 142857256042496.0000; encoder init loss: 18.2707; \n",
      "p loss: 0.3715; noise regularize:0.5959; mse loss: 0.0747; encoder loss: 166942023352320.0000; encoder init loss: 18.5018; \n",
      "p loss: 0.3721; noise regularize:0.5959; mse loss: 0.0757; encoder loss: 153486478016512.0000; encoder init loss: 18.7353; \n",
      "p loss: 0.3705; noise regularize:0.5959; mse loss: 0.0742; encoder loss: 170923944574976.0000; encoder init loss: 18.9699; \n",
      "p loss: 0.3734; noise regularize:0.5959; mse loss: 0.0737; encoder loss: 140461947748352.0000; encoder init loss: 19.2067; \n",
      "p loss: 0.3782; noise regularize:0.5959; mse loss: 0.0755; encoder loss: 113526974709760.0000; encoder init loss: 19.4434; \n",
      "p loss: 0.3715; noise regularize:0.5959; mse loss: 0.0743; encoder loss: 132572872966144.0000; encoder init loss: 19.6818; \n",
      "p loss: 0.3771; noise regularize:0.5959; mse loss: 0.0742; encoder loss: 213467860566016.0000; encoder init loss: 19.9224; \n",
      "p loss: 0.3733; noise regularize:0.5959; mse loss: 0.0749; encoder loss: 147215959982080.0000; encoder init loss: 20.1636; \n",
      "p loss: 0.3749; noise regularize:0.5959; mse loss: 0.0752; encoder loss: 149141984378880.0000; encoder init loss: 20.4059; \n",
      "p loss: 0.3765; noise regularize:0.5959; mse loss: 0.0738; encoder loss: 216875883560960.0000; encoder init loss: 20.6537; \n",
      "p loss: 0.3708; noise regularize:0.5959; mse loss: 0.0740; encoder loss: 169795223814144.0000; encoder init loss: 20.9044; \n",
      "p loss: 0.3759; noise regularize:0.5959; mse loss: 0.0754; encoder loss: 111870249795584.0000; encoder init loss: 21.1563; \n",
      "p loss: 0.3698; noise regularize:0.5959; mse loss: 0.0743; encoder loss: 130209877590016.0000; encoder init loss: 21.4076; \n",
      "p loss: 0.3748; noise regularize:0.5959; mse loss: 0.0745; encoder loss: 156766625071104.0000; encoder init loss: 21.6610; \n",
      "p loss: 0.3729; noise regularize:0.5959; mse loss: 0.0752; encoder loss: 148954129891328.0000; encoder init loss: 21.9145; \n",
      "p loss: 0.3756; noise regularize:0.5959; mse loss: 0.0763; encoder loss: 153187424141312.0000; encoder init loss: 22.1701; \n",
      "p loss: 0.3827; noise regularize:0.5959; mse loss: 0.0755; encoder loss: 198198211641344.0000; encoder init loss: 22.4222; \n",
      "p loss: 0.3825; noise regularize:0.5959; mse loss: 0.0762; encoder loss: 206663105642496.0000; encoder init loss: 22.6795; \n",
      "p loss: 0.3739; noise regularize:0.5959; mse loss: 0.0784; encoder loss: 178235958624256.0000; encoder init loss: 22.9422; \n",
      "p loss: 0.3796; noise regularize:0.5959; mse loss: 0.0763; encoder loss: 96598654713856.0000; encoder init loss: 23.2059; \n",
      "p loss: 0.3736; noise regularize:0.5959; mse loss: 0.0738; encoder loss: 93227206049792.0000; encoder init loss: 23.4685; \n",
      "p loss: 0.3747; noise regularize:0.5959; mse loss: 0.0728; encoder loss: 127165064544256.0000; encoder init loss: 23.7285; \n",
      "p loss: 0.3728; noise regularize:0.5959; mse loss: 0.0741; encoder loss: 161524861632512.0000; encoder init loss: 23.9887; \n",
      "p loss: 0.3708; noise regularize:0.5959; mse loss: 0.0764; encoder loss: 170981674975232.0000; encoder init loss: 24.2500; \n",
      "p loss: 0.3752; noise regularize:0.5959; mse loss: 0.0750; encoder loss: 169738936254464.0000; encoder init loss: 24.5157; \n",
      "p loss: 0.3708; noise regularize:0.5959; mse loss: 0.0740; encoder loss: 167298874736640.0000; encoder init loss: 24.7837; \n",
      "p loss: 0.3767; noise regularize:0.5959; mse loss: 0.0747; encoder loss: 180529001398272.0000; encoder init loss: 25.0496; \n",
      "p loss: 0.3695; noise regularize:0.5959; mse loss: 0.0756; encoder loss: 175928688771072.0000; encoder init loss: 25.3187; \n",
      "p loss: 0.3734; noise regularize:0.5959; mse loss: 0.0755; encoder loss: 165805249527808.0000; encoder init loss: 25.5911; \n",
      "p loss: 0.3700; noise regularize:0.5959; mse loss: 0.0741; encoder loss: 131044376313856.0000; encoder init loss: 25.8664; \n",
      "p loss: 0.3714; noise regularize:0.5959; mse loss: 0.0739; encoder loss: 163771028865024.0000; encoder init loss: 26.1397; \n",
      "p loss: 0.3701; noise regularize:0.5959; mse loss: 0.0740; encoder loss: 251745749958656.0000; encoder init loss: 26.4157; \n",
      "p loss: 0.3694; noise regularize:0.5959; mse loss: 0.0765; encoder loss: 211806278647808.0000; encoder init loss: 26.6947; \n",
      "p loss: 0.3700; noise regularize:0.5959; mse loss: 0.0762; encoder loss: 146160102670336.0000; encoder init loss: 26.9778; \n",
      "p loss: 0.3674; noise regularize:0.5959; mse loss: 0.0731; encoder loss: 141780460765184.0000; encoder init loss: 27.2609; \n",
      "p loss: 0.3706; noise regularize:0.5959; mse loss: 0.0727; encoder loss: 183714659172352.0000; encoder init loss: 27.5428; \n",
      "p loss: 0.3670; noise regularize:0.5959; mse loss: 0.0751; encoder loss: 191954520375296.0000; encoder init loss: 27.8293; \n",
      "p loss: 0.3705; noise regularize:0.5959; mse loss: 0.0771; encoder loss: 179077520556032.0000; encoder init loss: 28.1155; \n",
      "p loss: 0.3696; noise regularize:0.5959; mse loss: 0.0740; encoder loss: 146315510022144.0000; encoder init loss: 28.4046; \n",
      "p loss: 0.3698; noise regularize:0.5959; mse loss: 0.0718; encoder loss: 149070798651392.0000; encoder init loss: 28.6953; \n",
      "p loss: 0.3685; noise regularize:0.5959; mse loss: 0.0731; encoder loss: 143549081321472.0000; encoder init loss: 28.9856; \n",
      "p loss: 0.3683; noise regularize:0.5959; mse loss: 0.0751; encoder loss: 190713023168512.0000; encoder init loss: 29.2753; \n",
      "p loss: 0.3692; noise regularize:0.5959; mse loss: 0.0748; encoder loss: 260485656084480.0000; encoder init loss: 29.5691; \n",
      "p loss: 0.3665; noise regularize:0.5959; mse loss: 0.0736; encoder loss: 191619580035072.0000; encoder init loss: 29.8646; \n",
      "p loss: 0.3671; noise regularize:0.5959; mse loss: 0.0735; encoder loss: 148670309728256.0000; encoder init loss: 30.1607; \n",
      "p loss: 0.3652; noise regularize:0.5959; mse loss: 0.0729; encoder loss: 189311840419840.0000; encoder init loss: 30.4599; \n",
      "p loss: 0.3649; noise regularize:0.5959; mse loss: 0.0736; encoder loss: 172508502294528.0000; encoder init loss: 30.7613; \n",
      "p loss: 0.3648; noise regularize:0.5959; mse loss: 0.0757; encoder loss: 144723469664256.0000; encoder init loss: 31.0658; \n",
      "p loss: 0.3651; noise regularize:0.5959; mse loss: 0.0732; encoder loss: 211907747250176.0000; encoder init loss: 31.3714; \n",
      "p loss: 0.3654; noise regularize:0.5959; mse loss: 0.0726; encoder loss: 226736054730752.0000; encoder init loss: 31.6795; \n",
      "p loss: 0.3635; noise regularize:0.5959; mse loss: 0.0734; encoder loss: 220402907348992.0000; encoder init loss: 31.9887; \n",
      "p loss: 0.3644; noise regularize:0.5959; mse loss: 0.0730; encoder loss: 177479960494080.0000; encoder init loss: 32.2993; \n",
      "p loss: 0.3638; noise regularize:0.5959; mse loss: 0.0729; encoder loss: 145200529801216.0000; encoder init loss: 32.6113; \n",
      "p loss: 0.3627; noise regularize:0.5959; mse loss: 0.0723; encoder loss: 214271858311168.0000; encoder init loss: 32.9263; \n",
      "p loss: 0.3631; noise regularize:0.5959; mse loss: 0.0732; encoder loss: 229627373027328.0000; encoder init loss: 33.2373; \n",
      "p loss: 0.3617; noise regularize:0.5959; mse loss: 0.0751; encoder loss: 166167050190848.0000; encoder init loss: 33.5487; \n",
      "p loss: 0.3624; noise regularize:0.5959; mse loss: 0.0727; encoder loss: 165314683731968.0000; encoder init loss: 33.8647; \n",
      "p loss: 0.3612; noise regularize:0.5959; mse loss: 0.0722; encoder loss: 201830562791424.0000; encoder init loss: 34.1822; \n",
      "p loss: 0.3605; noise regularize:0.5959; mse loss: 0.0730; encoder loss: 196139781455872.0000; encoder init loss: 34.5017; \n",
      "p loss: 0.3610; noise regularize:0.5959; mse loss: 0.0735; encoder loss: 164536019582976.0000; encoder init loss: 34.8220; \n",
      "p loss: 0.3615; noise regularize:0.5959; mse loss: 0.0723; encoder loss: 164772561551360.0000; encoder init loss: 35.1448; \n",
      "p loss: 0.3636; noise regularize:0.5959; mse loss: 0.0721; encoder loss: 177145506693120.0000; encoder init loss: 35.4703; \n",
      "p loss: 0.3671; noise regularize:0.5959; mse loss: 0.0731; encoder loss: 204377545506816.0000; encoder init loss: 35.7938; \n",
      "p loss: 0.3623; noise regularize:0.5959; mse loss: 0.0731; encoder loss: 208583694221312.0000; encoder init loss: 36.1213; \n",
      "p loss: 0.3616; noise regularize:0.5959; mse loss: 0.0732; encoder loss: 190421300936704.0000; encoder init loss: 36.4485; \n",
      "p loss: 0.3615; noise regularize:0.5959; mse loss: 0.0717; encoder loss: 209981169205248.0000; encoder init loss: 36.7791; \n",
      "p loss: 0.3638; noise regularize:0.5959; mse loss: 0.0722; encoder loss: 203361685078016.0000; encoder init loss: 37.1122; \n",
      "p loss: 0.3681; noise regularize:0.5959; mse loss: 0.0727; encoder loss: 166750813421568.0000; encoder init loss: 37.4445; \n",
      "p loss: 0.3639; noise regularize:0.5959; mse loss: 0.0714; encoder loss: 181657067847680.0000; encoder init loss: 37.7786; \n",
      "p loss: 0.3689; noise regularize:0.5959; mse loss: 0.0725; encoder loss: 204482872868864.0000; encoder init loss: 38.1135; \n",
      "p loss: 0.3682; noise regularize:0.5959; mse loss: 0.0748; encoder loss: 215713692254208.0000; encoder init loss: 38.4490; \n",
      "p loss: 0.3658; noise regularize:0.5959; mse loss: 0.0736; encoder loss: 214267009695744.0000; encoder init loss: 38.7913; \n",
      "p loss: 0.3728; noise regularize:0.5959; mse loss: 0.0722; encoder loss: 199674992525312.0000; encoder init loss: 39.1372; \n",
      "p loss: 0.3697; noise regularize:0.5959; mse loss: 0.0717; encoder loss: 177978814234624.0000; encoder init loss: 39.4816; \n",
      "p loss: 0.3705; noise regularize:0.5959; mse loss: 0.0738; encoder loss: 196489972285440.0000; encoder init loss: 39.8326; \n",
      "p loss: 0.3650; noise regularize:0.5959; mse loss: 0.0752; encoder loss: 243934747951104.0000; encoder init loss: 40.1791; \n",
      "p loss: 0.3694; noise regularize:0.5959; mse loss: 0.0757; encoder loss: 265137088888832.0000; encoder init loss: 40.5275; \n",
      "p loss: 0.3661; noise regularize:0.5959; mse loss: 0.0728; encoder loss: 202706182471680.0000; encoder init loss: 40.8745; \n",
      "p loss: 0.3692; noise regularize:0.5959; mse loss: 0.0724; encoder loss: 160008134197248.0000; encoder init loss: 41.2271; \n",
      "p loss: 0.3629; noise regularize:0.5959; mse loss: 0.0720; encoder loss: 169958902333440.0000; encoder init loss: 41.5797; \n",
      "p loss: 0.3650; noise regularize:0.5959; mse loss: 0.0723; encoder loss: 254792559493120.0000; encoder init loss: 41.9317; \n",
      "p loss: 0.3641; noise regularize:0.5959; mse loss: 0.0754; encoder loss: 325679954526208.0000; encoder init loss: 42.2833; \n",
      "p loss: 0.3630; noise regularize:0.5959; mse loss: 0.0752; encoder loss: 306084703109120.0000; encoder init loss: 42.6411; \n",
      "p loss: 0.3614; noise regularize:0.5959; mse loss: 0.0720; encoder loss: 249503558926336.0000; encoder init loss: 42.9987; \n",
      "p loss: 0.3619; noise regularize:0.5959; mse loss: 0.0703; encoder loss: 213829812224000.0000; encoder init loss: 43.3575; \n",
      "p loss: 0.3609; noise regularize:0.5959; mse loss: 0.0709; encoder loss: 187233277575168.0000; encoder init loss: 43.7198; \n",
      "p loss: 0.3613; noise regularize:0.5959; mse loss: 0.0719; encoder loss: 197624011423744.0000; encoder init loss: 44.0758; \n",
      "p loss: 0.3599; noise regularize:0.5959; mse loss: 0.0718; encoder loss: 224147967836160.0000; encoder init loss: 44.4351; \n",
      "p loss: 0.3599; noise regularize:0.5959; mse loss: 0.0719; encoder loss: 279739021393920.0000; encoder init loss: 44.7924; \n",
      "p loss: 0.3597; noise regularize:0.5959; mse loss: 0.0725; encoder loss: 280180547387392.0000; encoder init loss: 45.1514; \n",
      "p loss: 0.3586; noise regularize:0.5959; mse loss: 0.0719; encoder loss: 233774885371904.0000; encoder init loss: 45.5175; \n",
      "p loss: 0.3585; noise regularize:0.5959; mse loss: 0.0705; encoder loss: 203649565327360.0000; encoder init loss: 45.8860; \n",
      "p loss: 0.3579; noise regularize:0.5959; mse loss: 0.0695; encoder loss: 224407964352512.0000; encoder init loss: 46.2501; \n",
      "p loss: 0.3574; noise regularize:0.5959; mse loss: 0.0711; encoder loss: 234098182324224.0000; encoder init loss: 46.6179; \n",
      "p loss: 0.3581; noise regularize:0.5959; mse loss: 0.0722; encoder loss: 233214694129664.0000; encoder init loss: 46.9890; \n",
      "p loss: 0.3555; noise regularize:0.5959; mse loss: 0.0697; encoder loss: 222651607941120.0000; encoder init loss: 47.3625; \n",
      "p loss: 0.3564; noise regularize:0.5959; mse loss: 0.0699; encoder loss: 212325432819712.0000; encoder init loss: 47.7361; \n",
      "p loss: 0.3556; noise regularize:0.5959; mse loss: 0.0698; encoder loss: 219714722725888.0000; encoder init loss: 48.1092; \n",
      "p loss: 0.3546; noise regularize:0.5959; mse loss: 0.0705; encoder loss: 261173287059456.0000; encoder init loss: 48.4802; \n",
      "p loss: 0.3556; noise regularize:0.5959; mse loss: 0.0711; encoder loss: 244519501037568.0000; encoder init loss: 48.8556; \n",
      "p loss: 0.3559; noise regularize:0.5959; mse loss: 0.0698; encoder loss: 213062523027456.0000; encoder init loss: 49.2331; \n",
      "p loss: 0.3533; noise regularize:0.5959; mse loss: 0.0694; encoder loss: 221176286674944.0000; encoder init loss: 49.6122; \n",
      "p loss: 0.3531; noise regularize:0.5959; mse loss: 0.0702; encoder loss: 221298777128960.0000; encoder init loss: 49.9924; \n",
      "p loss: 0.3554; noise regularize:0.5959; mse loss: 0.0705; encoder loss: 210468899651584.0000; encoder init loss: 50.3700; \n",
      "p loss: 0.3554; noise regularize:0.5959; mse loss: 0.0700; encoder loss: 209916727918592.0000; encoder init loss: 50.7455; \n",
      "p loss: 0.3549; noise regularize:0.5959; mse loss: 0.0694; encoder loss: 198350833975296.0000; encoder init loss: 51.1226; \n",
      "p loss: 0.3532; noise regularize:0.5959; mse loss: 0.0704; encoder loss: 212094058233856.0000; encoder init loss: 51.5011; \n",
      "p loss: 0.3538; noise regularize:0.5959; mse loss: 0.0710; encoder loss: 269692723789824.0000; encoder init loss: 51.8845; \n",
      "p loss: 0.3532; noise regularize:0.5959; mse loss: 0.0704; encoder loss: 240344054628352.0000; encoder init loss: 52.2679; \n",
      "p loss: 0.3511; noise regularize:0.5959; mse loss: 0.0695; encoder loss: 232833348009984.0000; encoder init loss: 52.6533; \n",
      "p loss: 0.3525; noise regularize:0.5959; mse loss: 0.0691; encoder loss: 208043534974976.0000; encoder init loss: 53.0419; \n",
      "p loss: 0.3536; noise regularize:0.5959; mse loss: 0.0693; encoder loss: 196772081172480.0000; encoder init loss: 53.4303; \n",
      "p loss: 0.3520; noise regularize:0.5959; mse loss: 0.0690; encoder loss: 202825703358464.0000; encoder init loss: 53.8203; \n",
      "p loss: 0.3533; noise regularize:0.5959; mse loss: 0.0689; encoder loss: 197115527561216.0000; encoder init loss: 54.2134; \n",
      "p loss: 0.3541; noise regularize:0.5959; mse loss: 0.0705; encoder loss: 250467493871616.0000; encoder init loss: 54.6051; \n",
      "p loss: 0.3527; noise regularize:0.5959; mse loss: 0.0704; encoder loss: 292612061790208.0000; encoder init loss: 55.0007; \n",
      "p loss: 0.3566; noise regularize:0.5959; mse loss: 0.0706; encoder loss: 214223321825280.0000; encoder init loss: 55.3977; \n",
      "p loss: 0.3524; noise regularize:0.5959; mse loss: 0.0699; encoder loss: 216378237779968.0000; encoder init loss: 55.7964; \n",
      "p loss: 0.3578; noise regularize:0.5959; mse loss: 0.0697; encoder loss: 278216405155840.0000; encoder init loss: 56.1977; \n",
      "p loss: 0.3599; noise regularize:0.5959; mse loss: 0.0717; encoder loss: 168998457049088.0000; encoder init loss: 56.5978; \n",
      "p loss: 0.3556; noise regularize:0.5959; mse loss: 0.0702; encoder loss: 172036626317312.0000; encoder init loss: 56.9972; \n",
      "p loss: 0.3617; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 310226829967360.0000; encoder init loss: 57.3853; \n",
      "p loss: 0.3530; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 273113782681600.0000; encoder init loss: 57.7812; \n",
      "p loss: 0.3582; noise regularize:0.5959; mse loss: 0.0709; encoder loss: 216879993978880.0000; encoder init loss: 58.1805; \n",
      "p loss: 0.3524; noise regularize:0.5959; mse loss: 0.0694; encoder loss: 264450028339200.0000; encoder init loss: 58.5779; \n",
      "p loss: 0.3560; noise regularize:0.5959; mse loss: 0.0697; encoder loss: 255795182698496.0000; encoder init loss: 58.9775; \n",
      "p loss: 0.3513; noise regularize:0.5959; mse loss: 0.0693; encoder loss: 183575458611200.0000; encoder init loss: 59.3794; \n",
      "p loss: 0.3549; noise regularize:0.5959; mse loss: 0.0694; encoder loss: 185474924675072.0000; encoder init loss: 59.7807; \n",
      "p loss: 0.3544; noise regularize:0.5959; mse loss: 0.0692; encoder loss: 252741611945984.0000; encoder init loss: 60.1803; \n",
      "p loss: 0.3551; noise regularize:0.5959; mse loss: 0.0709; encoder loss: 265686140059648.0000; encoder init loss: 60.5827; \n",
      "p loss: 0.3509; noise regularize:0.5959; mse loss: 0.0710; encoder loss: 239487930073088.0000; encoder init loss: 60.9959; \n",
      "p loss: 0.3522; noise regularize:0.5959; mse loss: 0.0700; encoder loss: 217950179033088.0000; encoder init loss: 61.4026; \n",
      "p loss: 0.3513; noise regularize:0.5959; mse loss: 0.0681; encoder loss: 213320372060160.0000; encoder init loss: 61.8055; \n",
      "p loss: 0.3499; noise regularize:0.5959; mse loss: 0.0683; encoder loss: 213362617090048.0000; encoder init loss: 62.2086; \n",
      "p loss: 0.3509; noise regularize:0.5959; mse loss: 0.0705; encoder loss: 207643482259456.0000; encoder init loss: 62.6138; \n",
      "p loss: 0.3512; noise regularize:0.5959; mse loss: 0.0695; encoder loss: 249038662270976.0000; encoder init loss: 63.0185; \n",
      "p loss: 0.3509; noise regularize:0.5959; mse loss: 0.0694; encoder loss: 256074020028416.0000; encoder init loss: 63.4232; \n",
      "p loss: 0.3504; noise regularize:0.5959; mse loss: 0.0693; encoder loss: 191453082943488.0000; encoder init loss: 63.8274; \n",
      "p loss: 0.3505; noise regularize:0.5959; mse loss: 0.0692; encoder loss: 206832438083584.0000; encoder init loss: 64.2292; \n",
      "p loss: 0.3493; noise regularize:0.5959; mse loss: 0.0697; encoder loss: 272584092418048.0000; encoder init loss: 64.6354; \n",
      "p loss: 0.3505; noise regularize:0.5959; mse loss: 0.0698; encoder loss: 240826567360512.0000; encoder init loss: 65.0345; \n",
      "p loss: 0.3491; noise regularize:0.5959; mse loss: 0.0684; encoder loss: 182669220511744.0000; encoder init loss: 65.4341; \n",
      "p loss: 0.3482; noise regularize:0.5959; mse loss: 0.0675; encoder loss: 181972932493312.0000; encoder init loss: 65.8314; \n",
      "p loss: 0.3499; noise regularize:0.5959; mse loss: 0.0677; encoder loss: 211838373462016.0000; encoder init loss: 66.2195; \n",
      "p loss: 0.3474; noise regularize:0.5959; mse loss: 0.0708; encoder loss: 226780262694912.0000; encoder init loss: 66.6105; \n",
      "p loss: 0.3468; noise regularize:0.5959; mse loss: 0.0700; encoder loss: 226644048478208.0000; encoder init loss: 66.9969; \n",
      "p loss: 0.3487; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 223537713381376.0000; encoder init loss: 67.3768; \n",
      "p loss: 0.3463; noise regularize:0.5959; mse loss: 0.0681; encoder loss: 215714816327680.0000; encoder init loss: 67.7530; \n",
      "p loss: 0.3464; noise regularize:0.5959; mse loss: 0.0693; encoder loss: 198922316283904.0000; encoder init loss: 68.1294; \n",
      "p loss: 0.3469; noise regularize:0.5959; mse loss: 0.0692; encoder loss: 228454880509952.0000; encoder init loss: 68.4992; \n",
      "p loss: 0.3465; noise regularize:0.5959; mse loss: 0.0683; encoder loss: 242309488705536.0000; encoder init loss: 68.8652; \n",
      "p loss: 0.3474; noise regularize:0.5959; mse loss: 0.0682; encoder loss: 218498106130432.0000; encoder init loss: 69.2236; \n",
      "p loss: 0.3457; noise regularize:0.5959; mse loss: 0.0687; encoder loss: 219118745681920.0000; encoder init loss: 69.5817; \n",
      "p loss: 0.3459; noise regularize:0.5959; mse loss: 0.0683; encoder loss: 229603096395776.0000; encoder init loss: 69.9283; \n",
      "p loss: 0.3467; noise regularize:0.5959; mse loss: 0.0684; encoder loss: 204990568202240.0000; encoder init loss: 70.2664; \n",
      "p loss: 0.3449; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 214303852462080.0000; encoder init loss: 70.5968; \n",
      "p loss: 0.3462; noise regularize:0.5959; mse loss: 0.0684; encoder loss: 236045614448640.0000; encoder init loss: 70.9246; \n",
      "p loss: 0.3478; noise regularize:0.5959; mse loss: 0.0689; encoder loss: 206773701050368.0000; encoder init loss: 71.2470; \n",
      "p loss: 0.3461; noise regularize:0.5959; mse loss: 0.0689; encoder loss: 194233537396736.0000; encoder init loss: 71.5619; \n",
      "p loss: 0.3469; noise regularize:0.5959; mse loss: 0.0691; encoder loss: 237682617745408.0000; encoder init loss: 71.8683; \n",
      "p loss: 0.3460; noise regularize:0.5959; mse loss: 0.0690; encoder loss: 266903847174144.0000; encoder init loss: 72.1684; \n",
      "p loss: 0.3456; noise regularize:0.5959; mse loss: 0.0689; encoder loss: 246132378697728.0000; encoder init loss: 72.4637; \n",
      "p loss: 0.3459; noise regularize:0.5959; mse loss: 0.0689; encoder loss: 211559636795392.0000; encoder init loss: 72.7528; \n",
      "p loss: 0.3449; noise regularize:0.5959; mse loss: 0.0681; encoder loss: 233836843630592.0000; encoder init loss: 73.0317; \n",
      "p loss: 0.3458; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 259549705535488.0000; encoder init loss: 73.3091; \n",
      "p loss: 0.3452; noise regularize:0.5959; mse loss: 0.0696; encoder loss: 244340119044096.0000; encoder init loss: 73.5788; \n",
      "p loss: 0.3449; noise regularize:0.5959; mse loss: 0.0687; encoder loss: 222688987578368.0000; encoder init loss: 73.8346; \n",
      "p loss: 0.3436; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 231160256921600.0000; encoder init loss: 74.0826; \n",
      "p loss: 0.3440; noise regularize:0.5959; mse loss: 0.0692; encoder loss: 234686290853888.0000; encoder init loss: 74.3203; \n",
      "p loss: 0.3428; noise regularize:0.5959; mse loss: 0.0691; encoder loss: 242136263950336.0000; encoder init loss: 74.5436; \n",
      "p loss: 0.3434; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 250154363912192.0000; encoder init loss: 74.7580; \n",
      "p loss: 0.3428; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 250339836035072.0000; encoder init loss: 74.9597; \n",
      "p loss: 0.3425; noise regularize:0.5959; mse loss: 0.0689; encoder loss: 237453071876096.0000; encoder init loss: 75.1454; \n",
      "p loss: 0.3423; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 219027578290176.0000; encoder init loss: 75.3191; \n",
      "p loss: 0.3422; noise regularize:0.5959; mse loss: 0.0680; encoder loss: 214336668696576.0000; encoder init loss: 75.4768; \n",
      "p loss: 0.3420; noise regularize:0.5959; mse loss: 0.0682; encoder loss: 225262226636800.0000; encoder init loss: 75.6269; \n",
      "p loss: 0.3418; noise regularize:0.5959; mse loss: 0.0688; encoder loss: 233181039034368.0000; encoder init loss: 75.7647; \n",
      "p loss: 0.3416; noise regularize:0.5959; mse loss: 0.0688; encoder loss: 225016725635072.0000; encoder init loss: 75.8949; \n",
      "p loss: 0.3414; noise regularize:0.5959; mse loss: 0.0684; encoder loss: 215070957109248.0000; encoder init loss: 76.0220; \n",
      "p loss: 0.3414; noise regularize:0.5959; mse loss: 0.0682; encoder loss: 215287735517184.0000; encoder init loss: 76.1405; \n",
      "p loss: 0.3411; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 231188711079936.0000; encoder init loss: 76.2513; \n",
      "p loss: 0.3410; noise regularize:0.5959; mse loss: 0.0690; encoder loss: 242922947608576.0000; encoder init loss: 76.3531; \n",
      "p loss: 0.3409; noise regularize:0.5959; mse loss: 0.0688; encoder loss: 233964484689920.0000; encoder init loss: 76.4465; \n",
      "p loss: 0.3406; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 212500637286400.0000; encoder init loss: 76.5358; \n",
      "p loss: 0.3406; noise regularize:0.5959; mse loss: 0.0684; encoder loss: 208074103062528.0000; encoder init loss: 76.6221; \n",
      "p loss: 0.3404; noise regularize:0.5959; mse loss: 0.0684; encoder loss: 220182739943424.0000; encoder init loss: 76.7047; \n",
      "p loss: 0.3404; noise regularize:0.5959; mse loss: 0.0684; encoder loss: 231908453646336.0000; encoder init loss: 76.7831; \n",
      "p loss: 0.3402; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 230071616929792.0000; encoder init loss: 76.8574; \n",
      "p loss: 0.3401; noise regularize:0.5959; mse loss: 0.0687; encoder loss: 221303374086144.0000; encoder init loss: 76.9279; \n",
      "p loss: 0.3400; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 220219129724928.0000; encoder init loss: 76.9963; \n",
      "p loss: 0.3400; noise regularize:0.5959; mse loss: 0.0684; encoder loss: 223298000519168.0000; encoder init loss: 77.0592; \n",
      "p loss: 0.3399; noise regularize:0.5959; mse loss: 0.0683; encoder loss: 225968748756992.0000; encoder init loss: 77.1151; \n",
      "p loss: 0.3398; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 228426694787072.0000; encoder init loss: 77.1639; \n",
      "p loss: 0.3397; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 227819879661568.0000; encoder init loss: 77.2075; \n",
      "p loss: 0.3396; noise regularize:0.5959; mse loss: 0.0687; encoder loss: 226979525689344.0000; encoder init loss: 77.2439; \n",
      "p loss: 0.3395; noise regularize:0.5959; mse loss: 0.0687; encoder loss: 226423209984000.0000; encoder init loss: 77.2767; \n",
      "p loss: 0.3395; noise regularize:0.5959; mse loss: 0.0687; encoder loss: 226753503035392.0000; encoder init loss: 77.3042; \n",
      "p loss: 0.3394; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 227733510553600.0000; encoder init loss: 77.3284; \n",
      "p loss: 0.3394; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 228663488413696.0000; encoder init loss: 77.3515; \n",
      "p loss: 0.3393; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 226699614617600.0000; encoder init loss: 77.3722; \n",
      "p loss: 0.3393; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 222828339134464.0000; encoder init loss: 77.3906; \n",
      "p loss: 0.3393; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 221183182110720.0000; encoder init loss: 77.4072; \n",
      "p loss: 0.3392; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 222217765912576.0000; encoder init loss: 77.4216; \n",
      "p loss: 0.3392; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 223745432092672.0000; encoder init loss: 77.4334; \n",
      "p loss: 0.3391; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 224642207842304.0000; encoder init loss: 77.4437; \n",
      "p loss: 0.3391; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 224825045942272.0000; encoder init loss: 77.4533; \n",
      "p loss: 0.3391; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 224855479812096.0000; encoder init loss: 77.4604; \n",
      "p loss: 0.3390; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 224923729526784.0000; encoder init loss: 77.4663; \n",
      "p loss: 0.3390; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 224924534833152.0000; encoder init loss: 77.4716; \n",
      "p loss: 0.3390; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225074774802432.0000; encoder init loss: 77.4765; \n",
      "p loss: 0.3390; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 224898563702784.0000; encoder init loss: 77.4809; \n",
      "p loss: 0.3389; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 224629104836608.0000; encoder init loss: 77.4844; \n",
      "p loss: 0.3389; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 224545269088256.0000; encoder init loss: 77.4875; \n",
      "p loss: 0.3389; noise regularize:0.5959; mse loss: 0.0685; encoder loss: 224854003417088.0000; encoder init loss: 77.4895; \n",
      "p loss: 0.3389; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225324553994240.0000; encoder init loss: 77.4911; \n",
      "p loss: 0.3389; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225596932096000.0000; encoder init loss: 77.4925; \n",
      "p loss: 0.3389; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225603206774784.0000; encoder init loss: 77.4935; \n",
      "p loss: 0.3389; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225389884473344.0000; encoder init loss: 77.4943; \n",
      "p loss: 0.3388; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225113899270144.0000; encoder init loss: 77.4947; \n",
      "p loss: 0.3388; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 224952032690176.0000; encoder init loss: 77.4950; \n",
      "p loss: 0.3388; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 224910760738816.0000; encoder init loss: 77.4953; \n",
      "p loss: 0.3388; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 224951613259776.0000; encoder init loss: 77.4954; \n",
      "p loss: 0.3388; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225031086931968.0000; encoder init loss: 77.4955; \n",
      "p loss: 0.3388; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225094236372992.0000; encoder init loss: 77.4956; \n",
      "p loss: 0.3388; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225133360840704.0000; encoder init loss: 77.4956; \n",
      "p loss: 0.3388; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225155590651904.0000; encoder init loss: 77.4956; \n",
      "p loss: 0.3388; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225166160297984.0000; encoder init loss: 77.4956; \n",
      "p loss: 0.3388; noise regularize:0.5959; mse loss: 0.0686; encoder loss: 225170790809600.0000; encoder init loss: 77.4957; \n"
     ]
    }
   ],
   "source": [
    "for i in pbar:\n",
    "    t = i / args.step\n",
    "    lr = get_lr(t, args.lr)\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    \n",
    "    if args.no_noises:\n",
    "        img_gen, img_seg = g_ema([latent_in], input_is_latent=True)\n",
    "    else:\n",
    "        img_gen, img_seg = g_ema([latent_in], input_is_latent=True, noise=noises)\n",
    "\n",
    "    batch, channel, height, width = img_gen.shape\n",
    "    \n",
    "    if height > 256:\n",
    "        factor = height // 256\n",
    "\n",
    "        img_gen = img_gen.reshape(\n",
    "    batch, channel, height // factor, factor, width // factor, factor\n",
    "        )\n",
    "        img_gen = img_gen.mean([3, 5])\n",
    "\n",
    "    p_loss = percept(img_gen, target_img_tensor).mean()\n",
    "    \n",
    "    mse_loss = F.mse_loss(img_gen, target_img_tensor)\n",
    "\n",
    "    n_loss = noise_regularize(noises)\n",
    "\n",
    "    encoder_init_loss = F.mse_loss(latent_in, latent_enc_init)\n",
    "    encoder_loss = F.mse_loss(latent_in, encoder(img_gen).detach())\n",
    "\n",
    "    # main loss function\n",
    "    loss = p_loss + \\\n",
    "       args.noise_regularize * n_loss + \\\n",
    "       mse_loss * args.lambda_mse + \\\n",
    "       encoder_loss * args.lambda_encoder + \\\n",
    "       encoder_init_loss * args.lambda_encoder_init\n",
    "\n",
    "    print(\n",
    "    (\n",
    "        f'p loss: {p_loss.item():.4f}; noise regularize:{n_loss.item():.4f}; mse loss: {mse_loss.item():.4f}; '\n",
    "        f'encoder loss: {encoder_loss.item():.4f}; encoder init loss: {encoder_init_loss.item():.4f}; '\n",
    "    )\n",
    "        )\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    noise_normalize_(noises)\n",
    "\n",
    "    latent_path.append(latent_in.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    if args.no_noises:\n",
    "        img_gen, img_seg = g_ema([latent_path[-1]], input_is_latent=True)\n",
    "    else:\n",
    "        img_gen, img_seg = g_ema([latent_path[-1]], input_is_latent=True, noise=noises,\n",
    "                    truncation=args.truncation, truncation_latent=tru_mean_latent)\n",
    "\n",
    "    img_gen = img_gen.cpu()\n",
    "    img_seg = img_seg.cpu()\n",
    "\n",
    "    img_gen = make_image(img_gen).squeeze()\n",
    "\n",
    "    if args.seg_dim != 1:\n",
    "        mask_gen = torch.argmax(img_seg, dim=1).squeeze().type(torch.uint8).numpy()\n",
    "    else:\n",
    "        mask_gen = torch.sigmoid(img_seg)\n",
    "        mask_gen[mask_gen>0.5] = 1.0\n",
    "        mask_gen = mask_gen.squeeze().type(torch.uint8).numpy()\n",
    "\n",
    "    img_seg = make_mask(args, img_seg).squeeze()\n",
    "\n",
    "    img_gen_pil = Image.fromarray(img_gen)\n",
    "    img_seg_pil = Image.fromarray(img_seg)\n",
    "    mask_gen_pil = Image.fromarray(mask_gen)\n",
    "\n",
    "    pil_target_overlay = overlay_img_and_mask(args, target_pil, img_seg_pil)\n",
    "    pil_gen_overlay = overlay_img_and_mask(args, img_gen_pil, img_seg_pil)\n",
    "\n",
    "    if args.dataset_name == 'celeba-mask':\n",
    "        if img_p.endswith('.jpg'):\n",
    "            img_p = img_p.replace('.jpg', '.png')\n",
    "\n",
    "    img_gen_pil.save('recon_'+img_p)\n",
    "    pil_gen_overlay.save('recon_overlay_'+img_p)\n",
    "    mask_gen_pil.save('mask_'+img_p)\n",
    "    img_seg_pil.save('mask_rgb_'+img_p)\n",
    "    pil_target_overlay.save('target_overlay_'+img_p)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "missing-you",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
