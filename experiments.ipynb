{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import argparse\n",
    "\n",
    "from semanticGAN_code.models.stylegan2_seg import GeneratorSeg\n",
    "from semanticGAN_code.models.encoder_model import FPNEncoder\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torchvision import transforms\n",
    "from semanticGAN_code.models import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rgb(args, mask):\n",
    "    if args.dataset_name == 'celeba-mask':\n",
    "        color_table = torch.tensor(\n",
    "                        [[  0,   0,   0],\n",
    "                        [ 0,0,205],\n",
    "                        [132,112,255],\n",
    "                        [ 25,25,112],\n",
    "                        [187,255,255],\n",
    "                        [ 102,205,170],\n",
    "                        [ 227,207,87],\n",
    "                        [ 142,142,56]], dtype=torch.float)\n",
    "\n",
    "    else:\n",
    "        raise Exception('No such a dataloader!')\n",
    "\n",
    "    rgb_tensor = F.embedding(mask, color_table).permute(0,3,1,2)\n",
    "    return rgb_tensor\n",
    "\n",
    "def make_mask(args, tensor, threshold=0.5):\n",
    "    if args.seg_dim == 1:\n",
    "        seg_prob = torch.sigmoid(tensor)\n",
    "        seg_mask = torch.zeros_like(tensor)\n",
    "        seg_mask[seg_prob > threshold] = 1.0\n",
    "        seg_mask = (seg_mask.to('cpu')\n",
    "                       .mul(255)\n",
    "                       .type(torch.uint8)\n",
    "                       .permute(0, 2, 3, 1)\n",
    "                       .numpy())\n",
    "    else:\n",
    "        seg_prob = torch.argmax(tensor, dim=1)\n",
    "        seg_mask = mask2rgb(args, seg_prob)\n",
    "        seg_mask = (seg_mask.to('cpu')\n",
    "                       .type(torch.uint8)\n",
    "                       .permute(0, 2, 3, 1)\n",
    "                       .numpy())\n",
    "    \n",
    "\n",
    "    return seg_mask\n",
    "\n",
    "def make_image(tensor):\n",
    "    return (\n",
    "        tensor.detach()\n",
    "        .clamp_(min=-1, max=1)\n",
    "        .add(1)\n",
    "        .div_(2)\n",
    "        .mul(255)\n",
    "        .type(torch.uint8)\n",
    "        .permute(0, 2, 3, 1)\n",
    "        .to('cpu')\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "\n",
    "def overlay_img_and_mask(args, img_pil, mask_pil, alpha=0.3):\n",
    "    img_pil = img_pil.convert('RGBA')\n",
    "    mask_pil = mask_pil.convert('RGBA')\n",
    "\n",
    "    overlay_pil = Image.blend(img_pil, mask_pil, alpha)\n",
    "    \n",
    "    return overlay_pil\n",
    "\n",
    "def noise_regularize(noises):\n",
    "    loss = 0\n",
    "\n",
    "    for noise in noises:\n",
    "        size = noise.shape[2]\n",
    "\n",
    "        while True:\n",
    "            loss = (\n",
    "                loss\n",
    "                + (noise * torch.roll(noise, shifts=1, dims=3)).mean().pow(2)\n",
    "                + (noise * torch.roll(noise, shifts=1, dims=2)).mean().pow(2)\n",
    "            )\n",
    "\n",
    "            if size <= 8:\n",
    "                break\n",
    "\n",
    "            noise = noise.reshape([1, 1, size // 2, 2, size // 2, 2])\n",
    "            noise = noise.mean([3, 5])\n",
    "            size //= 2\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def noise_normalize_(noises):\n",
    "    for noise in noises:\n",
    "        mean = noise.mean()\n",
    "        std = noise.std()\n",
    "\n",
    "        noise.data.add_(-mean).div_(std)\n",
    "\n",
    "def get_lr(t, initial_lr, rampdown=0.25, rampup=0.05):\n",
    "    lr_ramp = min(1, (1 - t) / rampdown)\n",
    "    lr_ramp = 0.5 - 0.5 * math.cos(lr_ramp * math.pi)\n",
    "    lr_ramp = lr_ramp * min(1, t / rampup)\n",
    "\n",
    "    return initial_lr * lr_ramp\n",
    "\n",
    "def get_transformation(args):\n",
    "    if args.dataset_name == 'celeba-mask':\n",
    "        transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                ]\n",
    "            )\n",
    "    elif args.dataset_name == 'cxr':\n",
    "        transform = transforms.Compose(\n",
    "                        [\n",
    "                            HistogramEqualization(),\n",
    "                            AdjustGamma(0.5),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5,), (0.5,)),\n",
    "                        ]\n",
    "                    )\n",
    "    elif args.dataset_name == 'isic':\n",
    "        transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                ]\n",
    "            )\n",
    "    else:\n",
    "        raise Exception('No such a dataloader!')\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--dataset_name', type=str, help='segmentation dataloader name [celeba-mask|cxr|isic]', default='celeba-mask')\n",
    "parser.add_argument('--size', type=int, default=256)\n",
    "parser.add_argument('--channel_multiplier', type=int, default=2)\n",
    "parser.add_argument('--image_mode', type=str, default='RGB')\n",
    "parser.add_argument('--batch_size', type=int, default=1)\n",
    "parser.add_argument('--seg_dim', type=int, default=8)\n",
    "parser.add_argument('--gpu_ids', type=int, nargs='+', default=[0])\n",
    "\n",
    "parser.add_argument('--mean_init', action='store_true', help='initialize latent code with mean')\n",
    "parser.add_argument('--no_noises', action='store_true')\n",
    "parser.add_argument('--w_plus', action='store_true', help='optimize in w+ space, otherwise w space')\n",
    "\n",
    "parser.add_argument('--save_latent', action='store_true')\n",
    "parser.add_argument('--save_steps', action='store_true', help='if to save intermediate optimization results')\n",
    "\n",
    "parser.add_argument('--truncation', type=float, default=1, help='truncation tricky, trade-off between quality and diversity')\n",
    "parser.add_argument('--truncation_mean', type=int, default=4096)\n",
    "\n",
    "parser.add_argument('--lr_rampup', type=float, default=0.05)\n",
    "parser.add_argument('--lr_rampdown', type=float, default=0.25)\n",
    "parser.add_argument('--lr', type=float, default=0.1)\n",
    "parser.add_argument('--noise', type=float, default=0.05)\n",
    "parser.add_argument('--noise_ramp', type=float, default=0.75)\n",
    "parser.add_argument('--step', type=int, default=100, help='optimization steps [100-500 should give good results]')\n",
    "parser.add_argument('--noise_regularize', type=float, default=1e2)\n",
    "parser.add_argument('--lambda_mse', type=float, default=0.1)\n",
    "parser.add_argument('--lambda_mean', type=float, default=0.01)\n",
    "parser.add_argument('--lambda_label', type=float, default=1.0)\n",
    "parser.add_argument('--lambda_encoder', type=float, default=1e-3)\n",
    "parser.add_argument('--lambda_encoder_init', type=float, default=0.0)\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "args.latent = 512\n",
    "args.n_mlp = 8\n",
    "tru_mean_latent = None\n",
    "d_input_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('gan_enc_14k.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPNEncoder(\n",
       "  (FPN_module): FPN(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (toplayer): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (smooth1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (smooth2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (smooth3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (latlayer1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (latlayer2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (latlayer3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (course_styles): ModuleList(\n",
       "    (0-2): 3 x ToStyleCode(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "      (linear): EqualLinear(512, 512)\n",
       "    )\n",
       "  )\n",
       "  (medium_styles): ModuleList(\n",
       "    (0-3): 4 x ToStyleCode(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (9): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "      (linear): EqualLinear(512, 512)\n",
       "    )\n",
       "  )\n",
       "  (fine_styles): ModuleList(\n",
       "    (0-6): 7 x ToStyleCode(\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (9): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (11): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "      (linear): EqualLinear(512, 512)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_ema = GeneratorSeg(args.size, args.latent, args.n_mlp, seg_dim=args.seg_dim, image_mode=args.image_mode,\n",
    "        channel_multiplier=args.channel_multiplier\n",
    "    ).to(device)\n",
    "g_ema.load_state_dict(checkpoint['g_ema'], strict=False)\n",
    "g_ema.eval()\n",
    "\n",
    "encoder = FPNEncoder(input_dim=d_input_dim, n_latent=g_ema.n_latent).to(device)\n",
    "encoder.load_state_dict(checkpoint['e'])\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "missing-you",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
